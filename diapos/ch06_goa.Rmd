---
output:
  xaringan::moon_reader:
    css: ["lib/columns.css", "lib/xaringan-themer.css", "lib/columns.css"]   
    lib_dir: lib
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    seal: false
---

```{r, echo=FALSE}
library(xaringanExtra)
xaringanExtra::use_tachyons()
```

background-image: url(fig/wall_rope.jpg)
background-size: cover

.white.b.f1[Causalité]  
.white.f3[Vincent Arel-Bundock]

---

background-image: url(fig/cesar.jpg)
background-size: cover

.white.f2[Plan]

.white[
* Théorie causale structurelle
* Graphes orientés acycliques
* Information causale vs. Information statistique
* Chemins
    - Fourchette
    - Chaîne
    - Collision
* Identification causale
* Exemples
* Simulations
]


---

.f-headline[Théorie  
causale  
structurelle]

---

# Théorie causale structurelle

.column75-left[
Raisonnement contre-factuel:

* Expérience de pensée des mondes alternatifs:
    - Avec aspirine
    - Avec placebo

Approche graphique:

1. Faire la liste des variables pertinentes pour la question de recherche.
2. Représenter graphiquement les relations causales entre ces variables.

Joie et allégresse!

* Est-ce que l'effet causal de $X$ sur $Y$ est identifiable?
* Le modèle statistique doit "ajuster" pour quelles variables?
]

.column25-right[
<img src="fig/pearl.jpg">
]

---

# Théorie causale structurelle: Exemple

.column50-left[
Effet causal:

* Éducation $\rightarrow$ Idéologie politique

Variables pertinentes:

* Éducation
* Idéologie politique
* Revenu individuel
* Revenu des parents
]

--

.column50-right[
Relations causales:

1. Éducation $\overset{+}{\rightarrow}$ Revenu individuel; 
2. Revenu individuel $\overset{+}{\rightarrow}$ droite politique;
3. Revenu des parents $\overset{+}{\rightarrow}$ éducation;
4. Revenu des parents $\overset{+}{\rightarrow}$ Revenu individuel.

Source: Connaissances du chercheur, études antérieures, etc.
]

---

# Théorie causale structurelle: Exemple

.column50-left[
<img src='fig/goa_ideologie.png'>
]

.column50-right[
Relations causales:

1. Éducation $\overset{+}{\rightarrow}$ Revenu individuel; 
2. Revenu individuel $\overset{+}{\rightarrow}$ droite politique;
3. Revenu des parents $\overset{+}{\rightarrow}$ éducation;
4. Revenu des parents $\overset{+}{\rightarrow}$ Revenu individuel.

Source: Connaissances du chercheur, études antérieures, etc.
]

---

# Théorie causale structurelle: Exemple

.column50-left[
<img src='fig/goa_ideologie.png'>
]

.column50-right[
Quel modèle de régression multiple employer pour estimer l'effet causal de l'éducation sur l'idéologie?

* Aucun contrôle?
* Contrôle pour revenu individuel?
* Contrôle pour revenu des parents?
* Contrôle pour les deux?
]

---

# Théorie causale structurelle: Exemple

.column50-left[
<img src='fig/goa_ideologie.png'>
]

.column50-right[
Quel modèle de régression multiple employer pour estimer l'effet causal de l'éducation sur l'idéologie?

* ~~Aucun contrôle?~~
* ~~Contrôle pour revenu individuel?~~
* .green[Contrôle pour revenu des parents]
* ~~Contrôle pour les deux?~~
]

---

# Pourquoi dessiner un graphique causal?

.column50-left[
3 fonctions principales :

1. *Transparence*
    - Révéler les postulats théoriques et les hypothèses de recherche de façon explicite et transparente.
2. *Identification*
    - Est-il possible d'estimer l'effet causal de la variable indépendante sur la variable dépendante? 
3. *Modélisation*
    - Quelles variables de contrôle qui doivent être *incluses* dans un modèle de régression multiple, et quelles variables doivent en être *exclues*.
]
.column50-right[
<img src = 'fig/frozen_bubble.jpg'>
]

---

background-image: url(fig/wall_nodes.jpg)
background-size: cover

.white.f-headline.b[Graphes Orientés Acycliques]

---

# GRAPHES orientés acycliques

.column25-left[
Représentation visuelle

Sommets (ou noeuds):

* Variables 
* Phénomènes

Flèches:

* Relations causales
]
.column75-right[
<img src='fig/goa_ideologie.png'>
]

---

# Graphes ORIENTÉS acycliques

.column50-left[
Le GOA est *orienté* parce que:

* Les flèches indiquent la direction de la relation causale qui lie les variables. 
* Les relations causales sont toujours unidirectionnelles.

$A$ cause $B$, et non l'inverse:

$$A \rightarrow B$$

$A$ cause $B$, $B$ cause $C$, et $A$ cause $C$:

$$A \rightarrow B \rightarrow C$$
]

--

.column50-right[

Définitions:
 
* Descendant
    - Une variable en aval dans le chemin
* Ancêtre
    - Une variable en amont dans le chemin

Un ancêtre cause un descendant, pas l'inverse.

Note: l'*absence* d'une flèche signifie qu'il n'y a *pas* de relation causale.
]

---

# Graphes orientés ACYCLIQUES

Le GOA ne contient pas de chemin circulaire qui nous ramène au point de départ, et où toutes les flèches pointent dans la même direction.

.column50-left[
Bon:
<center><img src='fig/goa_7.1.png' width='60%' /></center>
]
.column50-right[
Mauvais:
<center><img src='fig/goa_7.2.png' width='60%' /></center>
]

---

background-image: url(fig/wall_road.jpg)
background-size: cover
class: bottom

.white.b.f-headline[Chemins]

---

# Effet causal vs. Information statistique

Pour analyser un GOA, il est utile de distinguer deux phénomènes: l'effet causal et l'information statistique

* L'effet causal circule de la cause à l'effet, mais jamais de l'effet à la cause. 

* L'information statistique peut circuler dans les deux directions. 

La cause peut nous donner de l'information sur l'effet, et l'effet peut nous donner de l'information sur la cause.

---

# Effet causal vs. Information statistique

La pluie cause l'humidité du sol et non le contraire. La relation causale est unidirectionnelle.

<center><img src='fig/goa_7.3.png' width='30%' /></center>

Par contre, si nous voyons que le sol est humide, nous pouvons déduire qu'il a plu récemment. 

Le sol humide nous donne de l'information pertinente pour déduire (ou prédire) s’il y a eu de la pluie au cours des dernières heures. L'effet nous donne de l'information sur la cause. 

Même si les relations causales sont toujours unidirectionnelles, l'information statistique peut parfois circuler dans les deux directions. 

---

# Effet causal vs. Information statistique

Les individus qui ont des comportements sexuels risqués sont plus nombreux à contracter une infection transmise sexuellement (ITS), et à sentir une brulure à la miction:

<center><img src='fig/goa_7.4.png' width='50%' /></center>

La relation est unidirectionnelle. Par contre, l'information statistique circule dans les deux sens.

--

Chemin ouvert: 

> Quand l'information statistique circule entre $A$ et $C$.

Chemin fermé:

> Quand l'information statistique ne circule pas entre $A$ et $C$.


---

# Typologie des chemins

<img src="fig/fork.jpg" width="30%">
<img src="fig/chain.jpg" width="30%">
<img src="fig/collision_goats.jpg" width="30%">

3 structures causales:

1. Fourchette: $A \leftarrow B \rightarrow C$
1. Chaîne: $A \rightarrow B \rightarrow C$
1. Collision: $A \rightarrow B \leftarrow C$

Est-ce que ces chemins sont ouverts ou fermés?

---

# Fourchette: $A \leftarrow B \rightarrow C$

* 1 cause $B$
* 2 effets $A$ et $C$

<center><img src='fig/goa_7.5.png' width='70%' /></center>

--

## Fourchette = Ouverte

L'information statistique circule entre les extrémités:

* La colonne de mercure me permet de prédire le nombre de crèmes glacées vendues
* Le nombre de crèmes glacées vendues me permet de prédire la colonne de mercure

---

# Fourchette: $A \leftarrow B \rightarrow C$

<center><img src='fig/goa_7.5.png' width='70%' /></center>

Contrôler $\approx$ "Connaître," "Observer" ou "Fixer"

--

Si je connais la vraie température, la colonne de mercure est inutile pour prédire les crèmes glacées vendues.

--

### Contrôler pour le maillon central d'une fourchette ferme le chemin. 

L'information statistique ne circule plus.

---

# Chaîne: $a \rightarrow b \rightarrow c$

Séquence de 2 relations causales:

1. $A$ cause $B$ 
2. $B$ cause $C$. 

<center><img src='fig/goa_7.4.png' width='70%' /></center>

--

## Chaîne = Ouverte

L'information statistique circule entre les extrémités:

* Le comportement nous aide à prédire Pr(Brûlure)
* La brûlure nous aide à prédire le comportement

---

# Chaîne: $a \rightarrow b \rightarrow c$

<center><img src='fig/goa_7.4.png' width='70%' /></center>

### Contrôler pour le maillon central d'une chaîne ferme le chemin.

Si un test sanguin démontre qu'une personne ne souffre *pas* d'une ITS, le comportement à risque ne nous aide plus à prédire si elle souffre de brûlure à la miction.

Lorsque nous contrôlons ou observons le maillon central d'une chaîne, ses deux extrémités ne "communiquent" plus: le chemin devient fermé.

---

# Collision: $A \rightarrow B \leftarrow C$

* 2 causes $A$ et $C$
* 1 effet $B$

<center><img src='fig/goa_7.6.png' width='70%' /></center>

--

### Collision = Ouverte

L'information statistique ne circule *pas* entre les extrémités:

* Le biais d'un arbitre en faveur d'une équipe ne donne pas d'information sur la qualité du jeu de l'équipe. 
* La performance d'une équipe nous en dit peu sur le biais potentiel de l'arbitre.

---

# Collision: $A \rightarrow B \leftarrow C$

<center><img src='fig/goa_7.6.png' width='70%' /></center>

### Contrôler pour le maillon central d'une collision ferme le chemin.

Exemple: on observe que l'équipe a gagné.

* Si une équipe a gagné même si elle a mal joué, les chances que l'arbitre soit biaisé sont plus élevées. 
* Si une équipe a gagné même si l'arbitre n'était pas biaisé, les chances qu'elle ait bien joué sont plus hautes. 

Connaître le maillon central d'une collision permet de faire le lien entre ses extrémités. Lorsque le maillon central est fixé, les deux extrémités "communiquent."

---

# Fourchettes, chaînes et collisions

$$A \leftarrow B \rightarrow C \hspace{1in}\mbox{Ouvert} \\
A \rightarrow B \rightarrow C \hspace{1in}\mbox{Ouvert} \\
A \rightarrow B \leftarrow C \hspace{1in}\mbox{Fermé}$$

Contrôle pour une variable dans un modèle de régression multiple, c'est tracer un cadre autour de la variable. 

$$A \leftarrow \boxed{B} \rightarrow C \hspace{1in} \mbox{Fermé} \\
A \rightarrow \boxed{B} \rightarrow C \hspace{1in} \mbox{Fermé} \\
A \rightarrow \boxed{B} \leftarrow C \hspace{1in} \mbox{Ouvert}$$

Un modèle statistique qui contrôle pour le maillon central du chemin renverse le flot d'information: la fourchette et la chaîne deviennent fermées, et la collision devient ouverte:

---

# Chemins

Un chemin complexe est ouvert si et seulement si tous les maillons qui le composent sont ouverts. 

Dès qu'un seul des maillons est fermé, le chemin dans son ensemble est fermé.

Exemple 1:

$$A \leftarrow B \leftarrow C \leftarrow D \rightarrow E \hspace{1in} \mbox{Ouvert}$$

Exemple 2:

$$A \rightarrow B \leftarrow C \rightarrow D \rightarrow E \hspace{1in} \mbox{Fermé}$$

---

# Chemins

Si au moins un des maillons du chemin entre $A$ et $E$ est fermé, le chemin entier est fermé. Par exemple,

$$A \leftarrow B \leftarrow C \leftarrow \boxed{D} \rightarrow E \hspace{1in} \mbox{Fermé}\\
A \leftarrow \boxed{B} \leftarrow \boxed{C} \leftarrow \boxed{D} \rightarrow E \hspace{0.8in} \mbox{Fermé}\\
A \rightarrow \boxed{B} \leftarrow C \rightarrow D \rightarrow E \hspace{1in}\mbox{Ouvert}$$

Puisque que contrôler pour le descendant d'une collision renverse le flot d'information, ce chemin est ouvert:

<center><img src='fig/goa_7.8.png' width='35%' /></center>

---

# Cas spécial 1: Descendant d'une collision

Contrôler pour $D$ ouvre le chemin entre $A$ et $C$:

<center><img src='fig/goa_7.7.png' width='20%' /></center>

Le chemin entre $A$ et $C$ est fermé par la collision $A\rightarrow B\leftarrow C$. 

Si on contrôle pour $D$, le flot d'information est renversé, et le chemin entre $A$ et $C$ devient (partiellement) ouvert.

---

# Cas spécial 2: Chemin par la porte arrière

.column50-left[
Définition:

1. Le chemin par la porte arrière lie la cause $X$ à l'effet $Y$.
2. Une des extrémités du chemin pointe dans $X$.

<center><img src='fig/goa_7.14.png' width='35%' /></center>
]
.column50-right[
Ce GOA comprend 2 chemins entre la cause $X$ et l'effet $Y$:

1. $X \rightarrow Y$
1. $X \leftarrow Z \rightarrow Y$

Quel est le chemin par la porte arrière?

Est-ce que ce chemin est ouvert?

Et si je contrôle pour $Z$?
]

---

.column50-left[
.f1[Identification causale]
]
.column50-right[
<img src="fig/fingerprint.jpg">
]

---

# Identification causale

Les deux conditions suivantes sont suffisantes pour que l'effet causal de $X$ sur $Y$ soit identifiable:

.column50-left[
### 1. Le modèle statistique ne contrôle pas pour un descendant de $X$.

Quelles variables doit-on *exclure* du modèle?
]
.column50-right[

### 2. Tous les "chemins par la porte arrière" entre $X$ et $Y$ sont fermés.

Quelles variables doit-on *inclure* dans le modèle?
]

---

# Condition #1: Ne pas contrôler pour les descendants de $X$

.column50-left[

Un modèle statistique qui contrôle pour un descendant de $X$ n'identifiera pas l'effet causal total de $X$ sur $Y$.

Exemple:

<center><img src='fig/goa_7.9.png' width='55%' /></center>
]

.column50-right[

Le genre peut avoir un effet sur le salaire à travers (au moins) deux chemins : 

1. Une discrimination directe lors de la détermination des salaires. 
2. Une "discrimination structurelle," qui passe indirectement à travers l'occupation. 

Contrôler pour l'occupation nous donnerait un estimer "partiel" de l'effet "total" du genre sur les salaires.
]

---

# Condition #2: Bloquer les chemins par la porte arrière

Un "chemin par la porte arrière" est un chemin qui remplit deux conditions:

1. Le chemin lie la cause $X$ à l'effet $Y$.
2. Une des extrémités du chemin pointe dans $X$.

Quand les facteurs qui déterminent la valeur de $X$ sont liés à $Y$ (le chemin est ouvert), la condition #2 de l'identification causale est violée, et il est impossible d'estimer l'effet causal de $X$ sur $Y$.

---

# Condition #2: Bloquer les chemins par la porte arrière

Pour vérifier si tous les chemins par la porte arrière sont bloqués, il faut procéder en 2 étapes:

1. Trouver les chemins par la porte arrière
    - Faire la liste de tous les chemins qui lient la cause $X$ à l'effet $Y$
    - Identifier les chemins dont une extrémité pointe dans $X$
2. Vérifier si ces chemins sont ouverts

Intuitivement, un chemin par la porte arrière représente "les causes de la cause" (le chemin pointe dans $X$). 

Cette règle nous indique comment éliminer les relations fallacieuse ou les explications alternatives.

---

# Condition #2: Bloquer les chemins par la porte arrière

Exemple: Effet causal de l'éclatement familial sur la probabilité qu'une personne devienne itinérante: 

<center><img src='fig/goa_7.10.png' width='40%' /></center>

Ce GOA suggère qu'un trouble de santé mentale pourrait être une cause commune aux deux autres phénomènes; ce trouble pourrait augmenter la probabilité d'éclatement familial et d'itinérance :

$$\mbox{Éclatement familial} \leftarrow \boxed{\mbox{Santé mentale}} \rightarrow \mbox{Itinérance}$$

Pour estimer l'effet causal, il faut contrôler.

---

background-image: url(fig/wall_examples.jpg)
background-size: cover

.white.b.f-headline[Exemples]

---

# Éducation et idéologie politique

<center><img src='fig/goa_ideologie.png' width='60%' /></center>

La règle #1 de l'identification causale dit qu'il ne faut pas contrôler pour les descendants de la cause qui nous intéresse ("Éducation").

Notre modèle statistique ne devra *pas* contrôler pour la variable "Revenu individuel."

---

# Éducation et idéologie politique

<center><img src='fig/goa_ideologie.png' width='60%' /></center>

La règle #2 de l'identification causale dit qu'il faut fermer tous les chemins par la porte arrière. 

Ici, il y a un chemin par la porte arrière entre la variable indépendante et la variable dépendante :

<center><img src='fig/goa_7.11.png' width='60%' /></center>

---

# Éducation et idéologie politique

<center><img src='fig/goa_ideologie.png' width='60%' /></center>

Pour fermer ce chemin, nous pourrions contrôler pour "Revenu des parents" ou pour "Revenu individuel." 

Cependant, "Revenu individuel" est un descendant de "Éducation" : contrôler pour cette variable violerait la condition #1 de l'identification causale. 

Identifier l'effet causal de "Éducation" sur "Idéologie politique" requiert que nous contrôlions pour la variable "Revenu des parents," et que nous ne contrôlions *pas* pour la variable "Revenu individuel."

---

# Éducation et idéologie politique

<center><img src='fig/goa_ideologie.png' width='60%' /></center>

Ces stratégies pourraient être exprimées par le modèle linéaire suivant:

$$\mbox{Idéologie} = \beta_0 + \beta_1 \mbox{Éducation} + \beta_2 \mbox{Revenu des parents} + \varepsilon$$

---

# Exemples

<center><img src='fig/graphique_7.1.png' width='55%' /></center>

---

# Exemples

<center><img src='fig/graphique_7.1_a.png' width='15%' /></center>

Il n'y a aucun chemin par la porte arrière : pas besoin de contrôler pour quoi que ce soit. 

Afin d'estimer l'effet causal de $X$ sur $Y$, il suffit de mesurer l'association bivariée entre ces variables. 

---

# Exemples

<center><img src='fig/graphique_7.1_b.png' width='15%' /></center>

Il n'y a aucun chemin par la porte arrière.

Il est inutile de contrôler ; la régression bivariée suffit.

---

# Exemples

<center><img src='fig/graphique_7.1_c.png' width='15%' /></center>

Deux chemins lient $X$ à $Y$ : 
1. $X \rightarrow Y$. C'est le chemin causal qui nous intéresse. 
2. $X \rightarrow Z \leftarrow Y$. C'est un chemin non causal.

Il n'y a aucun chemin par la porte arrière, car aucune extrémité ne pointe vers $X$. 

$Z$ est un descendant de $X$ : contrôler pour $Z$ violerait la première condition de l'identification causale, ouvrirait le flot d'information sur ce chemin non causal, et biaiserait nos résultats.

---

# Exemples

<center><img src='fig/graphique_7.1_d.png' width='15%' /></center>

Il y a un chemin ouvert par la porte arrière : $X \leftarrow Z \rightarrow Y$. 

Il est essentiel de contrôler pour $Z$ si on veut estimer l'effet causal de $X$ sur $Y$.

---

# Exemples

<center><img src='fig/graphique_7.1_e.png' width='25%' /></center>

Il y a un chemin par la porte arrière: $X \leftarrow Z_2 \rightarrow Y$. 

Il est essentiel de contrôler pour $Z_2$ si nous voulons estimer l'effet causal de $X$ sur $Y$. 

Il est aussi important de ne pas contrôler pour $Z_1$, puisque cette variable est descendante de $X$.

---

# Exemples

<center><img src='fig/graphique_7.1_f.png' width='25%' /></center>

Il n'y a pas de chemin ouvert par la porte arrière. 

L'effet de $X$ sur $Y$ est identifiable, même si nous ne contrôlons pour aucune variable.

---

# Exemples

<center><img src='fig/graphique_7.1_g.png' width='20%' /></center>

Trois chemins lient les variables $X$ et $Y$:

$$\begin{align*}X \rightarrow Z_2 \rightarrow Y \\X \rightarrow Z_2 \rightarrow Z_3\leftarrow Y\\X \leftarrow Z_1 \rightarrow Y\end{align*}$$
---

# Exemples

<center><img src='fig/graphique_7.1_g.png' width='20%' /></center>

Les variables $Z_2$ et $Z_3$ sont descendantes de $X$ : il ne faut pas contrôler pour ces variables. 

Le troisième chemin est ouvert, et se termine par une flèche qui pointe vers $X$. Il est essentiel de bloquer ce chemin par la porte arrière en contrôlant pour $Z_1$. 

Pour estimer l'effet causal de $X$ sur $Y$, il faut contrôler pour $Z_1$ mais éviter de contrôler pour $Z_2$ ou $Z_3$.

---

background-image: url(fig/wall_laptop.jpg)
background-size: cover
class: center

.f-headline.white[Simulations]

---

# Simulations dans `R`

La fonction `rnorm(n)` pige $n$ nombres aléatoires dans une distribution normale.

```{r}
rnorm(2)
rnorm(5)
```

---

# Simulations dans `R`

1 000 000 de nombres aléatoires

```{r, eval=FALSE}
n <- 1000000
X <- rnorm(n)
```

```{r, include=FALSE}
n <- 1000000
X <- rnorm(200)
```

```{r}
X
```

---

# Simulations dans `R`

Deux variables indépendantes...

```{r}
X <- rnorm(n)

Y <- rnorm(n)

mod <- lm(Y ~ X)
coef(mod)
```

...sont indépendantes.

---

# Simulation 1: Relation causale simple

.column50-left[
Dans ce modèle, une augmentation d'une unité de $X$ cause une augmentation de 1,7 unité de $Y$.

<img src='fig/goa_7.15.png' width = "70%">
]

--

.column50-right[

```{r}
n <- 100000
X <- rnorm(n)
Y <- 1.7 * X + rnorm(n)

```

La fonction `lm` estime un modèle de régression linéaire:

```{r}
mod <- lm(Y ~ X)
coef(mod)
```
]

---

# Simulation 2: Chaîne

.column50-left[
Dans une chaîne de relations causales linéaires, l'effet causal est égal au produit des effets individuels. 

<center><img src='fig/goa_7.16.png'></center>

Le véritable effet de $X$ sur $Y$ dans ce GOA est $3 \cdot 0,5=1,5$
]

--

.column50-right[
```{r}
X <- rnorm(n)
Z <- 3 * X + rnorm(n)
Y <- 0.5 * Z + rnorm(n)

mod <- lm(Y ~ X)
coef(mod)
```
]

---

# Simulation 3: Collision

.column50-left[
<center><img src='fig/goa_7.17.png' width = "60%"></center>

Dans ce modèle, il n'y a pas de chemin par la porte arrière : aucun contrôle n'est requis.
]

--

.column50-right[
```{r}
X <- rnorm(n)
Y <- 1.7 * X + rnorm(n)
Z <- 1.2 * X + 0.8 * Y + rnorm(n)

mod <- lm(Y ~ X)
coef(mod)
```
]

---

# Simulation 3: Collision

.column50-left[
<center><img src='fig/goa_7.17.png' width = "60%"></center>

$Z$ est un descendant de $X$ : il est important de ne pas contrôler pour cette variable.
]

.column50-right[

```{r}
X <- rnorm(n)
Y <- 1.7 * X + rnorm(n)
Z <- 1.2 * X + 0.8 * Y + rnorm(n)

mod <- lm(Y ~ X + Z)
coef(mod)
```
]

---

# Simulation 4: Fourchette

.column50-left[
<center><img src='fig/goa_7.18.png' width='70%' /></center>

Le vrai effet causal de $X$ sur $Y$ est égal à: $2\cdot 0,25=0,5$. 

Il faut:

* Contrôler pour $Z_2$: Porte arrière
* Ne *pas* contrôler pour $Z_1$: Descendant
]


.column50-right[

```{r, message=FALSE}
n <- 100000
Z2 <- rnorm(n)
X <- Z2 + rnorm(n)
Z1 <- 2 * X + rnorm(n)
Y <- 0.25 * Z1 + Z2 + rnorm(n)

mod <- list()
mod[[1]] <- lm(Y ~ X + Z2)
mod[[2]] <- lm(Y ~ X)
mod[[3]] <- lm(Y ~ X + Z2 + Z1)
```
]

---

# Simulation 4: Fourchette

```{r}
library(modelsummary)
modelsummary(mod)
```

---

# Simulation 5: Modèle complexe

.column50-left[
<center><img src='fig/goa_7.19.png' width='80%' /></center>
]

.column50-right[
Le *vrai* effet causal de $X$ sur $Y$ est égal à $2\cdot 0.5=1$. 

Un modèle statistique non biaisé devait *inclure* $Z_1$, mais *exclure* $Z_2$ et $Z_3$.
]

---

# Simulation 5: Modèle complexe

.column50-left[
<center><img src='fig/goa_7.19.png' width='80%' /></center>
]
.column50-right[
```{r}
Z1 <- rnorm(n)
X <- Z1 + rnorm(n)
Z2 <- 2 * X + rnorm(n)
Y <- 0.5 * Z2 + Z1 + rnorm(n)
Z3 <- Z2 + Y + rnorm(n)
```
]

---

# Simulation 5: Modèle complexe

.column50-left[
<center><img src='fig/goa_7.19.png' width='80%' /></center>
]

.column50-right[
Nous estimons huit modèles avec différentes combinaisons des trois variables de contrôle $Z_1$, $Z_2$, et $Z_3$:

```{r}
mod <- list()
mod[[1]] <- lm(Y ~ X + Z1)
mod[[2]] <- lm(Y ~ X)
mod[[3]] <- lm(Y ~ X + Z2)
mod[[4]] <- lm(Y ~ X + Z3)
mod[[5]] <- lm(Y ~ X + Z1 + Z2)
mod[[6]] <- lm(Y ~ X + Z1 + Z3)
mod[[7]] <- lm(Y ~ X + Z2 + Z3)
mod[[8]] <- lm(Y ~ X + Z1 + Z2 + Z3)
```
]

---

# Simulation 5: Modèle complexe

Nous estimons huit modèles avec différentes combinaisons des trois variables de contrôle $Z_1$, $Z_2$, et $Z_3$:

```{r}
modelsummary(mod)
```

---

background-image: url(fig/wall_meditation.jpg)
background-size: cover
class: center

.f-headline.b[Leçons]

---

# 4 Leçons importantes

1. Quand nous connaissons le GOA, il est facile de voir quelles variables on doit inclure dans le modèle de régression.
2. Expériences aléatoires = WOW!
3. Biais post-traitement
4. Interprétation des variables de contrôle

---

# Expériences aléatoires

Les expériences aléatoires sont souvent considérées comme le "Gold Standard" de l'inférence causale. 

Si la valeur du traitement est déterminée de façon purement aléatoire, alors le traitement n'a aucun ancêtre. 

$$X \rightarrow Y$$

Aucune des flèches du GOA ne pointe vers la cause, et il n'existe aucun chemin par la porte arrière.

Dans une expérience où la valeur du traitement est aléatoire, la condition #2 de l'identification causale est *satisfaite automatiquement!*

---

# Biais post-traitement

Un "biais post-traitement" survient lorsqu'on contrôle pour un descendant de la cause, ce qui viole la première condition de l'identification causale. 

.column50-left[
Bloquer un chemin causal.
<center><img src='fig/goa_7.12.png' width='25%' /></center>
]
.column50-right[
Ouvrir un chemin *non* causal.
<center><img src='fig/goa_7.13.png' width='25%' /></center>
]

---

# Ne pas interpréter les variables de contrôle

<center><img src='fig/goa_7.14.png' width='15%' /></center>

Pour estimer l'effet causal de $X$, il faut contrôler pour $Z$:

$$Y = \beta_0 + \beta_1 X + \beta_2 Z + \varepsilon$$

--

Pour estimer l'effet causal de $Z$, il ne faut *pas* contrôler pour $X$:

$$Y = \alpha_0 + \alpha_1 Z + \nu$$

Deux modèles différents!

---

background-image: url(fig/please_clap.gif)
background-size: cover
