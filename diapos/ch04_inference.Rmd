---
output:
  xaringan::moon_reader:
    lib_dir: lib
    css: ["lib/columns.css", "lib/xaringan-themer.css"]
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    seal: false
---

```{r, echo=FALSE}
library(xaringanExtra)
xaringanExtra::use_tachyons()
```

background-image: url(fig/wall_squirrel.jpg)
background-size: cover

.b.white.f1[Inférence statistique]

.white.f3.tc[Vincent Arel-Bundock]

---

background-image: url(fig/wall_sample.jpg)
background-size: cover

.f1[
Échantillon  
et  
Population
]  

---

# Définitions

* Population
    - Ensemble des individus, objets, ou phénomènes pouvant potentiellement être observés. 
* Échantillon
    - Sous-groupe des objets qui composent la population.

--

# Types d'échantillons

* Échantillon probabiliste
    - Les individus qui font partie de l'échantillon ont été choisis à l'aide d'une procédure aléatoire. 
* Échantillon aléatoire simple
    - Tous les membres de la population ont la même probabilité d'être choisis.

---

background-image: url(fig/wall_dicebar.jpg)
background-size: cover

# Objectifs de l'inférence statistique

1. Estimer les caractéristiques d'une population à partir des caractéristiques d'un échantillon. 
2. Nous assurer que les caractéristiques estimées ne sont pas le fruit du pur hazard.

---

background-image: url(fig/wall_apple.jpg)
background-size: cover

.tr.white.f1[
Mise en  
situation
]

---

# Mise en situation

.column75-left[
> Une pomicultrice exploite un verger qui produit des centaines de milliers de pommes par automne. Elle aimerait vendre ses fruits à une chaîne de supermarchés qui accepte seulement les lots de pommes dont le poids moyen est inférieur à 100 grammes. La pomicultrice veut donc mesurer le poids moyen des pommes de son verger, pour s'assurer qu'il soit supérieur à 100.

> Puisque le verger produit un grand nombre de pommes, il serait trop onéreux de les peser une à une. Pour estimer leur poids, la pomicultrice tire donc un échantillon aléatoire de 50 pommes. Dans cet échantillon, le poids moyen est 105 grammes, et la variance des poids observés est égale à 300.
]
.column25-right[![](fig/pomme_bea.png)]

---

# Mise en situation

.column75-left[
> Une pomicultrice exploite un verger qui produit des centaines de milliers de pommes par automne. Elle aimerait vendre ses fruits à une chaîne de supermarchés qui accepte seulement les lots de pommes dont le poids moyen est inférieur à 100 grammes. La pomicultrice veut donc mesurer le poids moyen des pommes de son verger, pour s'assurer qu'il soit supérieur à 100.

> Puisque le verger produit un grand nombre de pommes, il serait trop onéreux de les peser une à une. Pour estimer leur poids, la pomicultrice tire donc un échantillon aléatoire de 50 pommes. Dans cet échantillon, le poids moyen est 105 grammes, et la variance des poids observés est égale à 300.
]
.column25-right[

Échantillon: $X$

Nombre d'observations: $n=50$

Variance des poids dans l'échantillon: $\sigma_X^2=300$

Poids moyen dans l'échantillon: $\bar{X}=105$

Poids moyen dans la population: $\mu=?$

]

---

.column50-left[
# Objectif

Démontrer à l'acheteur que $\mu>100$.

# Tâches

1. Estimation
    - Utiliser $\bar{X}$ pour estimer $\mu$
2. Test d'hypothèse
    - Écarter la possibilité que $\mu=100$
]

.column50-right[
<img src='fig/work_coffee.jpg'>
]

---

class: bottom right
background-image: url(fig/wall_electricity_estimation.png)
background-size: cover
  
---

# Définitions 

## Estimateur

--

* Fonction mathématique qui peut être appliquée à un échantillon pour obtenir de l'information sur les caractéristiques d'une population. 
* Exemple: Formule de la moyenne $\frac{1}{n}\sum_{i=1}^n X_i$

--

## Estimé

* La valeur produite par un estimateur dans un échantillon donné.
* Exemple: Moyenne des pommes de l'échantillon $\bar{X}$

---

# Deux propriétés d'un estimateur

.column40-left[
### 1. Biais

Si j'estimais la même statistique dans plusieurs échantillons différents, est-ce que j'obtiendrais le bon résultat *en moyenne*?

### 2. Variance échantillonnale

Est-ce que mon estimé risquerait de varier beaucoup si j'utilisais un échantillon différent?
]

.column60-right[
<img src='fig/parrot.jpg'>
]

---

# Biais vs. Variance échantillonnale

<center><img src='fig/graphique_5.1.png' width='70%' /></center>

---

# Biais

Un estimateur est *non biaisé* s'il produit la bonne réponse *en moyenne*, à travers différents échantillons.

--

Exemple hypothétique:

* La pomicultrice tire 10000 échantillons de 50 pommes.
* Elle calcule la moyenne du poids dans chaque échantillon: 10000 moyennes échantillonnales.
* La moyenne des 10000 moyennes échantillonales est égale à la moyenne de la population $\mu$.

--

Formellement, l'estimé est non-biaisé si son espérance est égale au paramètre de la population.

$$E[\bar{X}] = \mu$$

Équivalent:

$$E[\bar{X}] = E[X]$$


---

# Deux concepts distincts

.column50-left[
### 1. Variance *dans* l'échantillon

Dispersion des valeurs observées au sein d'un seul échantillon
]
.column50-right[
### 2. Variance *entre* échantillons 

"Variance échantillonnale"

Mesure comment nos résultats statistiques changent lorsqu'on les calcule à partir de différents échantillons, ou à travers différentes expériences. 
]


---

# Variance échantillonnale

<center>4 échantillons de 5 pommes</center>

<center><img src='fig/tableau_5.1.png' width='70%' /></center>

---

# Variance échantillonnale

.column50-left[
Variance échantillonnale *forte*:

* L'estimé risque de changer beaucoup si on utilisait un échantillon différent
* Beaucoup d'incertitude
* Peu de précision

Variance échantillonnale *faible*:

* L'estimé est stable d'un échantillon à l'autre
* Peu d'incertitude
* Beaucoup de précision
]

.column50-right[
<img src='fig/darts.jpg'>
]

---

# Variance échantillonnale de la moyenne

On estime cette statistique grâce à cette formule:

$$Var(\bar{X})=\frac{Var(X)}{n}$$

Voir la capsule vidéo suivante.

---

# Erreur type

Définition: 

> Racine carrée de la variation échantillonnale

$$\sigma_{\bar{X}} = \sqrt{\frac{\mbox{Var}(X)}{n}} = \sqrt{\frac{\sigma_{X}^2}{n}} = \frac{\sigma_X}{\sqrt{n}},$$

où $\sigma_X$ représente l'écart type des observations.

Mise en situation:

$$\sigma_{\bar{X}} = \sqrt{\frac{300}{50}}$$

---

# Biais vs. Variance échantillonnale: Résumé

.column50-left[
* Biais: 
    - Justesse
    - Est-ce que l'estimateur atteint la cible en moyenne?
    - $E[\bar{X}]=E[X]$
* Variance échantillonnale: 
    - Précision
    - Est-ce que les estimés varient beaucoup d'un échantillon à l'autre?
    - $Var(\bar{X})=\frac{Var(X)}{n}$
]
.column50-right[
<img src='fig/graphique_5.1.png'>
]

---

background-image: url(fig/wall_oyster.jpg)
background-size: cover

.tr.white.f1[Propriétés de la moyenne]

---

# Biais de la moyenne

.column50-left[
Règles de l'espérance:

1. $E[a \cdot X] = a \cdot E[X]$
2. $E[X_1+X_2] = E[X_1] + E[X_2]$

Espérance de la moyenne:

$$\bar{X} = \frac{1}{n} \cdot (X_1 + X_2 + ... + X_n)$$
$$E[\bar{X}] = E\left [ \frac{1}{n} \cdot (X_1 + X_2 + ... + X_n) \right ]$$
]

--

.column50-right[
Règle 1:

$$E[\bar{X}] = \frac{1}{n} E\left [X_1 + X_2 + ... + X_n \right ]$$

Règle 2:

$$E[\bar{X}] = \frac{1}{n} \left (E[X_1] + E[X_2] + ... + E[X_n] \right )$$

Postulat: tous les membres de l'échantillon sont pigés d'une même population:

\begin{align*}
E[\bar{X}] &= \frac{1}{n} \left (E[X] + E[X] + ... + E[X] \right )\\
&= \frac{1}{n} n E[X] = E[X]
\end{align*}
]

---

background-image: url(fig/wall_cheers.jpg)
background-size: cover
class: top

.tr.b.f3[La moyenne échantillonnale est non biaisée!]

---

# Variance échantillonnale de la moyenne

Règles de la variance:

1. $Var(a \cdot X) = a^2 \cdot Var(X)$
2. $Var(X_1 + X_2) = Var(X_1) + Var(X_2) + 2\cdot Cov(X_1, X_2)$

--

Si l'échantillon est aléatoire, les observations sont pigées de façon indépendante: $X_1 \perp X_2$. Par conséquent, 

$$Cov(X_1,X_2)=0$$

$$Var(X_1 + X_2) = Var(X_1) + Var(X_2)$$

---

# Variance échantillonnale de la moyenne

$$\bar{X} = \frac{1}{n} \cdot (X_1 + X_2 + ... + X_n)$$
$$Var(\bar{X}) = Var\left ( \frac{1}{n} \cdot (X_1 + X_2 + ... + X_n) \right )$$

Règle 1:

\begin{align*}
Var(\bar{X}) &= \frac{1}{n^2} \left (Var(X_1) + Var(X_2) + ... + Var(X_n) \right ) \\
\end{align*}

Règle 2 et échantillon aléatoire:

\begin{align*}
Var(\bar{X}) &= \frac{1}{n^2} \left (Var(X) + Var(X) + ... + Var(X) \right ) \\
             &= \frac{1}{n^2} n Var(X) = \frac{Var(X)}{n}
\end{align*}

---

# Variance échantillonnale de la moyenne

$$\sigma_{\bar{X}}^2=Var(\bar{X})=\frac{Var(X)}{n}$$

Dépend de:

1. La variance des observations: $Var(X)$ 
2. La taille de l'échantillon
    - Gros échantillon -> Bonne précision + Peu d'incertitude
    - Petit échantillon -> Mauvaise précision + Beaucoup d'incertitude

--

.bg-washed-red.b--dark-red.ba.bw2.br3.shadow-5.ph4.mt5[
### Cette formule motive les analyses quantitatives grands N!
]

---

background-image: url(fig/wall_question.jpg)
background-size: cover

.b.f1[
Quantifier

l'incertitude
]

---

background-image: url(fig/cesar.jpg)
background-size: cover

.f3.white[
Test d'hypothèse  
Hypothèse nulle  
Statistique $t$  
Valeur $p$  
Intervalle de confiance  
]

---

.column60-left[
# Test d'hypothèse

Stratégie:

1. Choisir une hypothèse de recherche
2. Vérifier si les données sont *compatibles* avec cette elle

Procédure: Combiner...

* Hypothèse de recherche
* Paramètre estimé
* Variance échantillonnale
]
.column40-right[
<img src='fig/pregnancy_test.jpg' width='90%'>
]

---

# Hypothèse nulle

Définition:

> Une phrase *déclarative* et *quantitative* qui pourrait potentiellement être infirmée par un test statistique.

--

Phrase déclarative: 

> Hypothèse nulle: Le poids moyen des pommes du verger est de 100 grammes.

--

Expression quantitative:

> $H_0: \mu = 100$

---

# Hypothèse nulle

Exemples:

* La moyenne du poids des pommes dans le verger est de 100 grammes.
* L'aspirine n'a aucun effet sur le mal de tête.
* Porter un masque n'a aucun effet sur le risque de transmission de la Covid-19
* Le genre d'un candidat n'a aucun effet sur la probabilité que cette personne soit élu.e

En pratique, plusieurs hypothèses nulles réfèrent à l'*absence* de relation entre deux variables, ou à un effet égal à 0.

---

# Test d'hypothèse nulle

.column50-left[
<img src='fig/whatif.jpg', width = "55%">
]
.column50-right[
## Question contre factuelle

* Si l'hypothèse nulle était vraie dans la population, quelle serait la probabilité d'observer des données comme celles de l'échantillon? 

## Outils

- Statistique $t$
- Valeur $p$
- Intervalle de confiance
]

---

# Statistique t

Hypothèse nulle:

> Le poids moyen des pommes du verger est égal à 100 grammes

Est-ce que ses données lui permettent de rejeter cette hypothèse nulle? 

La statistique $t$ répond à cette question en combinant deux informations:

1. Différence entre:
   - Estimé $\bar{X}$
   - Hypothèse nulle $\mu_0$
2. Précision de l'estimé
   - Variance échantillonnale
   - $Var{\bar{X}}$

---

# Statistique t: Estimé vs. Hypothèse nulle

Si l'hypothèse nulle est très différente de l'estimé, l'hypothèse nulle n'est pas "plausible."

--

.column50-left[
### Exemple 1

* Hypothèse nulle: 
    - Poids moyen des pommes dans la population = 100 grammes 
* Estimé: 
    - Poids moyen des pommes dans l'échantillon = 102 grammes
* Est-ce que l'hypothèse nulle est plausible?
]

--

.column50-right[
### Exemple 2

* Hypothèse nulle: 
    - Poids moyen des pommes dans la population = 50 grammes 
* Estimé: 
    - Poids moyen des pommes dans l'échantillon = 200 grammes
* Est-ce que l'hypothèse nulle est plausible?
]

---

# Statistique t: Estimé vs. Hypothèse nulle

Différence entre l'hypothèse nulle et l'estimé:

$$\mu_0-\bar{X}$$

Quand cette différence est *grande*, l'hypothèse nulle n'est *pas* plausible.

Quand cette différence est *faible*, l'hypothèse nulle est plausible.

Note: On compare $\mu_0$ à $\bar{X}$ en terme de valeur absolue.

--

.bg-washed-red.b--dark-red.ba.bw2.br3.shadow-5.ph4.mt5[
Quand la différence entre l'estimé et l'hypothèse nulle est faible, il est difficile de rejeter l'hypothèse nulle.
]

---

# Statistique t: Précision de l'estimé

Lorsque la variance échantillonnale $Var(\bar{X})$ est élevée, 

* l'estimé $\bar{X}$ varie beaucoup d'un échantillon à l'autre. 
* l'incertitude plane autour de notre estimé. 
* l'écart entre $\bar{X}$ et $\mu_0$ pourrait être le résultat de fluctuations aléatoires entre échantillons. 

--

.bg-washed-red.b--dark-red.ba.bw2.br3.shadow-5.ph4.mt5[
Quand l'erreur type est grande, il est difficile de rejeter l'hypothèse nulle.
]

---

# Statistique t

La statistique t combine l'information sur:

1. Différence entre l'estimé et l'hypothèse nulle
2. Précision de l'estimé (erreur type)

$$t = \frac{\bar{X}-\mu_0}{\sigma_{\bar{X}}},$$

Numérateur:

* Différence entre l'estimé et l'hypothèse nulle
* Plus la valeur absolue est élevée, moins l'hypothèse nulle est plausible.

Dénominateur:

* Précision (erreur type)
* Plus la valeur est élevée, plus il est facile de rejeter l'hypothèse nulle.

---

# Statistique t: Exemple des pommiers

.column50-left[
Hypothèse nulle:

$$ H_0: \mu_0 = 100$$

Taille de l'échantillon:

$$n=50$$

Poids moyen dans l'échantillon:

$$\bar{X}=105$$

Variance *dans* l'échantillon:

$$\sigma_X=300$$
]

--

.column50-right[
Variance échantillonnale:

$$\sigma_{\bar{X}}^2=\frac{\sigma_X}{n}=\frac{300}{50}$$

Erreur type:

$$\sigma_{\bar{X}}=\sqrt{\frac{300}{50}}=\sqrt{6}$$

Statistique t:

$$t = \frac{\bar{X}-\mu_0}{\sigma_{\bar{X}}}$$
$$t = \frac{105-100}{\sqrt{6}} = 2,04$$
]

---

# Statistique $t$

La statistique $t$ calculée par la pomicultrice dans son échantillon est égale à:

$$t = \frac{\bar{X}-\mu_0}{\sigma_{\bar{X}}} = \frac{105-100}{\sqrt{6}} = 2,04$$

Cette statistique $t$ s'interprète ainsi : 

* Plus la valeur $t$ s'éloigne de zéro, plus il serait surprenant d'observer un échantillon comme le nôtre, si l'hypothèse nulle était vraie. 
* Plus $|t|$ est grande, moins les données observées sont compatibles avec l'hypothèse nulle. 
* Plus $|t|$ est grande, plus il est raisonnable de croire que le poids moyen des pommes du verger est différent de 100.

---

# Distribution de t sous l'hypothèse nulle

.column50-left[
Imaginez que:

1. L'hypothèse nulle est vraie.
2. La chercheuse pige un très grand nombre d'échantillons aléatoires de taille $n$ indépendants.
3. Pour chaque échantillon, elle calcule une statistique t distincte.

Des statisticiens ont démontré que dans ces conditions, les statistiques t obtenues suivraient une loi de Student avec $n-1$ degrés de liberté.
]

.column50-right[
<img src='fig/graphique_5.2.png'>
]

---

# Distribution de t sous l'hypothèse nulle

.column50-left[
À l'oeil, on voit que la statistique t de la pomicultrice est inusitée: $t=2,04$ est loin du centre de la distribution. 

Si l'hypothèse nulle était vraie, des échantillons aléatoires produiraient rarement des valeurs $t$ aussi extrêmes que celle obtenue par la pomicultrice. 

Si le poids moyen des pommes du verger était égal à 100, il serait "étrange" de piger un échantillon de pommes comme celui de la pomicultrice. 

L'échantillon semble "incompatible" avec l'hypothèse nulle.
]

.column50-right[
<img src='fig/graphique_5.2.png'>
]

---

# Valeur p

Objectif:

* Mesurer la compatibilité des données et de l'hypothèse nulle. 

Mesure:

* Probabilité d'observer une statistique $t$ plus extrême que la notre si l'hypothèse nulle était vraie.

Procédure:

* Mesurer l'aire sous la courbe de la distribution $t$ sous l'hypothèse nulle. 

---

# Valeur p

.column50-left[
Si $t=2,04$, nous voulons connaître la probabilité d'observer $t>2,04$ ou $t<-2,04$:

<img src='fig/graphique_5.3.png'></center>
]

--

.column50-right[
Queue de gauche:
```{r}
pt(-2.04, df = 49)
```

Queue de droite:

```{r}
1 - pt(2.04, df = 49)
```

Extrêmes:

```{r}
pt(-2.04, df = 49) + (1 - pt(2.04, df = 49))
```
]

---

# Valeur p

La valeur $p$ de l'apicultrice est:

```{r}
pt(-2.04, df = 49) + (1 - pt(2.04, df = 49))
```

Si l'hypothèse nulle était vraie, la probabilité d'observer une statistique $t$ plus extrême que 2.04 serait inférieure à 5%. 

Si le poids moyen des pommes du verger était de 100 grammes, il serait très surprenant de piger un échantillon aléatoire de 50 pommes avec un poids moyen de 105 grammes.

---

# Valeur p

Interprétation

> Lorsque la valeur $p$ est très petite, les propriétés de l'échantillon seraient "étranges" ou "inusitées" si l'hypothèse nulle était vraie.

--

Convention

> En sciences sociales, plusieurs analystes adoptent un "seuil de signification statistique" de 0,05.

--

Décision

> Lorsque la valeur $p$ est plus petite que ce seuil, on "rejette l'hypothèse nulle," et on conclut que le paramètre estimé est "statistiquement significatif." 

--

Asymétrie

> Lorsque la valeur $p$ est plus grande que le seuil, on ne *rejette pas* l'hypothèse nulle. Important: Nous "n'acceptons" jamais l'hypothèse nulle.

---

# Intervalle de confiance

.column50-left[
Alternative pour représenter l'incertitude autour d'un estimé:

1. Choisir un seuil de signification statistique.
2. Construire un intervalle avec deux bornes qui correspondent à ce seuil.
3. Rejeter l'hypothèse nulle si l’estimé est à l'extérieur de l’intervalle.

Si on répétait une expérience plusieurs fois, 95% de nos intervalles de confiance "couvriraient" la vérité.
]
.column50-right[
<img src="fig/ringtoss.png">
]

---

# Intervalle de confiance

.column50-left[
Exemple:

* Hypothèse nulle: 100 grammes
* Moyenne des pommes de l'échantillon: 105 grammes
* Intervalle de confiance de niveau 95%: $[100,1; 109,9]$. 
* On peut rejeter l'hypothèse nulle

Note: La vérité est fixe et immuable. Lorsque nous calculons un intervalle de confiance de 95% à partir d'un nouvel échantillon, nous avons 95% de chances d'« entourer » la vérité.
]
.column50-right[
<img src="fig/ringtoss.png">
]

---

# Intervalle de confiance: Construction

.column50-left[
Pour construire un intervalle de confiance de 95%, on procède en trois étapes :

1. Identifier la région centrale qui couvre 95% de la distribution $t$. Les bornes de cette région sont les « seuils critiques ».
2. Multiplier les seuils critiques par l’erreur type.
3. Additionner à l'estimé.

Exemple: intervalle de 90% avec $\bar{X}=6$ et $\sigma_{\bar{X}}=1,5$.
]

.column50-right[
<img src='fig/graphique_5.4.png'>
]

---

# Intervalle de confiance: Construction 1/3

### Identifier les seuils critiques

Pour un intervalle de 90%, nous devons trouver la region centrale qui couvre 90% de la distribution $t$, soit la region entre le 5e et le 95e percentiles de la distribution $t$.

Nous utilisons la fonction `qt` dans `R`:

```{r}
qt(0.05, df = 49)
qt(0.95, df = 49)
```

---

# Intervalle de confiance: Construction 2/3

### Multiplier par l'erreur type

Si l’erreur type est $\sigma_{\bar{X}}=1,5$, on obtient:

$$-1,677 \cdot 1,5 = -2,5155$$
$$1,677 \cdot 1,5 = 2,5155$$

---

# Intervalle de confiance: Construction 3/3

### Additionner à l'estimé

Si l'estimé est $\bar{X}=6$, alors

$$[6 - 2,5155; 6 + 2,5155]$$
$$[3,4845; 8,5155]$$

---

# Intervalle de confiance: Interprétation

.column60-left[
> Si l'hypothèse nulle est vraie, 95% des intervalles de confiance construit de cette façon dans des échantillons aléatoires distincts couvriraient la vraie valeur du paramètre. 

Attention! Cela ne veut *pas* dire qu'il y a 95% de chances que la vraie valeur se trouve dans l'intervalle. L'intervalle bouge d'une expérience a l'autre, mais la vérité reste fixe!
]
.column40-right[
<img src="fig/ringtoss.png">
]

---

# Intervalle de confiance

Dans l'exemple de la pomicultrice, l'intervalle de confiance de 95% est égal à:

$$\begin{align}[105 - 2 \cdot \sqrt{6}; 105 + 2 \cdot \sqrt{6}]\\ [101,1; 109,9]\end{align}$$
Puisque 100 se trouve à l'extérieur de l'intervalle de confiance de 95%, nous pouvons rejeter l'hypothèse nulle selon laquelle le poids moyen des pommes est égal à 100 grammes, au seuil de signification statistique p<0,05. 

La différence entre l'hypothèse nulle et la moyenne estimée par la pomicultrice dans son échantillon est statistiquement significative au seuil de 5%.

---

# Le test d'hypothèse nulle, étape par étape

1. Choisir une hypothèse nulle que voulons tenter de rejeter.

1. Choisir un seuil de signification statistique au-dessous duquel nous sommes prêts à rejeter l’hypothèse nulle. 

1. Tirer un échantillon aléatoire.

1. Estimer une statistique dans l'échantillon.

1. Calculer l'erreur type de cette statistique.

1. Combiner l'estimé, l'hypothèse nulle, et l'erreur type pour calculer la statistique $t$.

1. Calculer la valeur $p$, soit la probabilité d’obtenir une statistique $t$ au moins aussi extrême que la nôtre si l’hypothèse nulle était vraie. 

1. Comparer la valeur $p$ au seuil de signification statistique choisi à l’étape 1 pour décider si nous rejetons l’hypothèse nulle.

---

background-image: url(fig/wall_pegasus.jpg)
background-size: cover
class: right

.f1.white.b[Limites]

---

# Les limites du test d'hypothèse nulle

Avantages:

* La valeur $p$ permet de quantifier la probabilité d'obtenir un estimé au moins aussi extrême que le notre si l'hypothèse nulle est vraie.
* Elle permet de mesurer le risque qu'un résultat soit purement le résultat soit purement le fruit du hasard échantillonnal.
* Cette information est utile, mais limitée.

---

# Les limites du test d'hypothèse nulle

.column60-left[
$p=0,05$ est un seuil arbitraire et subjectif, qui ne nous vient pas d'un argumentaire théorique, mais plutôt des préférences personnelles d'un statisticien eugéniste et raciste.
]
.column40-right[
<img src="fig/ronald-fisher.jpg" width = "70%">  
Ronald Fisher
]

---

# Les limites du test d'hypothèse nulle

1. Seuil arbitraire

--

2. Asymétrique: Impossible de démontrer que l'hypothèse nulle est *vraie*. (Voir "test d'équivalence").

--

3. Dépendance au modèle: valeur $p$ mesure la probabilité d'observer cet échantillon si l'hypothèse nulle est vraie *et que notre modèle est correct*.

--

4. Probabiliste: Pas de garantie!
	- Rejeter une hypothèse nulle même si elle est vraie: Erreur de type 1.
	- Ne pas rejeter une hypothèse nulle alors qu'elle est vraie: Erreur de type 2.

--

5. Grands échantillons
   - N -> Erreur type -> Statistique $t$ -> Valeur $p$
   - Tout est significatif dans un grand échantillon!
   - Réduire le seuil critique de $p$ quand la taille de l'échantillon augmente. (Approche Bayésienne de Leamer 1978)

---

# Les limites du test d'hypothèse nulle

.column50-left[
.bg-washed-red.b--dark-red.ba.bw2.br3.shadow-5.ph4.mt5[
Signification statistique $\neq$ Importance substantive
]

- Possible: Corrélation très faible *et* significative\
- Ne pas confondre *statistiquement significatif* et *important pour le domaine.*
]
.column50-right[
<img src="fig/cult_of_statistical_significance.jpg" width="60%">

Deirdre McCloskey & Stephen Ziliak
]

---

background-image: url(fig/wall_tomato.jpg)
background-size: cover
class: right

.tr.f-headline.white.b[Merci!]
