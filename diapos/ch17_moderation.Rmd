---
output:
  xaringan::moon_reader:
    css: ["lib/columns.css", "lib/xaringan-themer.css"]   
    lib_dir: lib
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    seal: false
---

```{r xaringanExtra, echo=FALSE}
library(xaringanExtra)
xaringanExtra::use_tachyons()
```

class: title
background-image: url(fig/wall_nest.jpg)
background-size: cover

.f2.white[Modération: Effets hétérogènes]

.f3.white[Vincent Arel-Bundock]

---

# Modération: Effets hétérogènes

Effets hétérogènes:

* L'effet causal est plus forts pour certaines unités d'observation que pour d'autres.
* L'aspirine a un effet plus puissant sur Vincent que sur Marcel.

Outil:

* Régression linéaire
* Interactions multiplicatives

---

# Effets hétérogènes: 2 exemples

3 variables:

* $X$: Cause
* $Y$: Effet
* $M$: Variable modératrice

--

Exemple 1:

> Le stress (X) a un effet négatif sur la santé psychologique (Y), mais cet effet est plus faible chez les gens qui bénéficient de l'appui d'un fort réseau social (M)

--

Exemple 2:

> Le manque de contrôle de soi (X) augmente la délinquance juvénile (Y), mais seulement chez les jeunes qui ont peu de supervision parentale (M)

---

background-image: url(fig/wall_mallet.jpg)
background-size: cover

.f1.white[Interactions]  
.f1.white[multiplicative]

---

# Interaction multiplicative

Modèle linéaire de base:

$$Y = \alpha_1 + \alpha_x X + \nu$$

Question:

* Est-ce que $M$ affecte la force de la relation entre $X$ et $Y$?

--

Stratégie:

1. Créer une nouvelle variable: $X \cdot M$
2. Ajouter cette variable au modèle linéaire

$$Y = \beta_1 + \beta_x X + \beta_m M + \beta_{xm} X \cdot M + \varepsilon$$

---

# Estimation

```{r eval=FALSE}
head(dat)
##             Y           X          M 
## 1  -1.9289906  0.01874617 -0.4006375 
## 2  -0.1934811 -0.18425254 -0.3345566 
## 3  -1.1332962 -1.37133055  1.3679540 
```

--

```{r eval=FALSE}
dat$XM <- dat$X * dat$M

head(dat)
##            Y           X          M          XM
## 1 -1.9289906  0.01874617 -0.4006375 -0.00751042
## 2 -0.1934811 -0.18425254 -0.3345566  0.06164290
## 3 -1.1332962 -1.37133055  1.3679540 -1.87591705
```

--

```{r eval=FALSE}
lm(Y ~ X + M + XM)
```

--

```{r eval=FALSE}
lm(Y ~ X * M)
```

---

# Exemples

Le stress (X) a un effet négatif sur la santé psychologique (Y), mais cet effet est plus faible chez les gens qui bénéficient de l'appui d'un fort réseau social (M)

$$\mbox{Santé} = \beta_1 + \beta_x \cdot \mbox{Stress} + \beta_m \cdot \mbox{Réseau} + \beta_{xm} \cdot \mbox{Stress} \cdot \mbox{Réseau} + \varepsilon$$

--

Le manque de contrôle de soi (X) augmente la délinquance juvénile (Y), mais seulement chez les jeunes qui ont peu de supervision parentale (M)

$$\begin{align*}
\mbox{Délinquance } = &\beta_1 + \beta_x \cdot \mbox{Contrôle de soi} + \beta_m \cdot \mbox{Supervision } + \\ &\beta_{xm} \cdot \mbox{Contrôle de soi} \cdot \mbox{Supervision} + \varepsilon
\end{align*}$$

---

background-image: url(fig/wall_oats.jpg)
background-size: cover
class: bottom right

.b.f1[Interprétation]

---

# Effet marginal

L'effet marginal est une mesure de l'association entre $X$ et $Y$:

Rappel:

> Dérivée partielle de l'équation de régression par rapport à la variable explicative.

Expression mathématique:

$$\frac{\partial Y}{\partial X}$$

--

Modèle:

$$Y = \beta_1 + \beta_x X + \beta_m M + \varepsilon$$

Effet marginal de $X$ sur $Y$:

$$\frac{\partial Y}{\partial X} = \beta_x$$

---

# Effet marginal

Modèle:

$$Y = \beta_1 + \beta_x X + \beta_m M + \beta_{xm} X \cdot M + \varepsilon$$

Effet marginal de $X$ sur $Y$:

$$\frac{\partial Y}{\partial X} = \beta_x + \beta_{xm}\cdot M$$

--

Important!

* Avec une interaction multiplicative, l'effet marginal devient une expression complexe. 
* La force de la relation entre $X$ et $Y$ dépend de la valeur de la variable modératrice $M$.
* Équation d'une droite. Représentation graphique.

---

# Effet marginal: Exemple

Le stress (X) a un effet négatif sur la santé psychologique (Y), mais cet effet est plus faible chez les gens qui bénéficient de l'appui d'un fort réseau social (M)

$$\mbox{Santé} = \beta_1 + \beta_x \cdot \mbox{Stress} + \beta_m \cdot \mbox{Réseau} + \beta_{xm} \cdot \mbox{Stress} \cdot \mbox{Réseau} + \varepsilon$$

$$\partial\mbox{Santé}/\partial\mbox{Stress}=\beta_x+\beta_{xm}SR$$

--

<center><img src='fig/mfx_stress.png' width='30%'></center>

---

# Effet marginal: Exemple

Le manque de contrôle de soi (X) augmente la délinquance juvénile (Y), mais seulement chez les jeunes qui ont peu de supervision parentale (M)

$$\begin{align*}
\mbox{Délinquance } = &\beta_1 + \beta_x \cdot \mbox{Contrôle de soi} + \beta_m \cdot \mbox{Supervision } + \\ &\beta_{xm} \cdot \mbox{Contrôle de soi} \cdot \mbox{Supervision} + \varepsilon
\end{align*}$$

$$\partial\mbox{Délinquance}/\partial{Contrôle}=\beta_x+\beta_{xm}SC$$

--

<center><img src='fig/mfx_controle.png' width='30%'></center>

---

# Effet marginal: Interprétation

$$\frac{\partial Y}{\partial X} = \beta_x + \beta_{xm}\cdot M$$

Les coefficients du modèle de régression avec interaction multiplicative doivent être interprétés ainsi: 

* $\beta_x + \beta_{xm} \cdot M$ mesure l'effet marginal de $X$ sur $Y$.
* $\beta_x$ mesure la force de l'association entre $X$ et $Y$ lorsque $M$ est égale à 0.
* $\beta_m$ mesure la force de l'association entre $X$ et $Y$ lorsque $M$ est égale à 0.
* $\beta_{xm}$ mesure l'effet de modération de $M$ sur la relation entre $X$ et $Y$.

---

# Effet marginal: Interprétation

.column50-left[
Pour interpréter, on remplace $\beta_x$ et $\beta_{xm}$ dans l'équation par les coefficients estimés. Par exemple, si 

$$\frac{\partial Y}{\partial X} = \beta_x + \beta_{xm}\cdot M$$

$$\frac{\partial Y}{\partial X} = 0,95 + 0,59 \cdot M$$
]

--

.column50-right[
L'effet de $X$ sur $Y$ dépend de la valeur de $M$:

Lorsque $M=-2$, une augmentation d'une unité de $X$ est associée à un changement de $0,95 + 0,59 \cdot -2 = -0,23$ dans $Y$.

Lorsque $M=0$, une augmentation d'une unité de $X$ est associée à un changement de $0,95 + 0,59 \cdot -2 = 0,95$ dans $Y$.

Lorsque $M=2$, une augmentation d'une unité de $X$ est associée à un changement de $0,95 + 0,59 \cdot 2 = 2,13$ dans $Y$.
]

---

background-image: url(fig/wall_lemur.jpg)
background-size: cover

.white.f1[Incertitude]

---

# Incertitude et test d'hypothèse nulle

Deux hypothèses nulles

H1: 

> La variable modératrice n'est pas associée à la force de l'effet marginal de $X$ sur $Y$.

H2: 

> L'effet marginal de $X$ sur $Y$ est égal à zéro lorsque $M=m$.

---

# Incertitude et test d'hypothèse nulle

H1: 

> La variable modératrice n'est pas associée à la force de l'effet marginal de $X$ sur $Y$.

Valeur $p$ associée au coefficient d'interaction $\beta_{xm}$.

```{r eval=FALSE}
summary(mod)
##             Estimate Std. Error t value Pr(>|t|)
## (Intercept)  0.02017    0.22974   0.088 0.930404
## X            0.94992    0.24814   3.828 0.000388
## M            1.96459    0.24854   7.904 4.09e-10
## X:M          0.58804    0.24755   2.375 0.021752
```

---

# Incertitude et test d'hypothèse nulle

H2:

> L'effet marginal de $X$ sur $Y$ est égal à zéro lorsque $M=m$.

Variance échantillonnale, erreur type, statistique $t$, et valeur $p$ de l'effet marginal (en entier!) pour toute les des valeurs de $M$. 

Règles de manipulation de la variance:

$$\begin{align}
\mbox{Var} \left (\frac{\partial Y}{\partial X} \right ) &= \mbox{Var} \left ( \beta_x + \beta_{xm}  M \right ) \\
                                                   &= \mbox{Var} \left ( \beta_x \right ) + 
                                                      \mbox{Var} \left (\beta_{xm}  M \right ) + 
                                                      2  \mbox{Cov} \left (\beta_x, \beta_{xm}  M \right ) \\
                                                   &= \mbox{Var} \left ( \beta_x \right ) + 
                                                      M^2 \cdot \mbox{Var} \left (\beta_{xm} \right ) + 
                                                      2M \cdot \mbox{Cov} \left (\beta_x, \beta_{xm} \right )
\end{align}$$

L'effet marginal est différent pour toutes valeurs de $M$. La variance échantillonale est aussi différente pour toutes valeurs de $M$.

---

# Incertitude et test d'hypothèse nulle

Matrice de variance-covariance

* Diagonale: Variances des coefficients
* Hors diagonale: Covariance

```{r eval=FALSE}
vcov(mod)
##              (Intercept)            X            M          X:M 
## (Intercept)  0.052779122  0.021363439 -0.006076704 -0.004166843 
## X            0.021363439  0.061574710 -0.004302670 -0.003991624 
## M           -0.006076704 -0.004302670  0.061774215  0.028777772 
## X:M         -0.004166843 -0.003991624  0.028777772  0.061282334
```

* $\mbox{Var}(\beta_x) = 0,0616$
* $\mbox{Var}(\beta_{xm}) = 0,0613$
* $\mbox{Cov}(\beta_x,\beta_{xm}) = -0,0040$

$$\begin{align}
\mbox{Var} \left (\frac{\partial Y}{\partial X} \right ) = \mbox{Var} \left ( \beta_x \right ) + 
                                                      M^2 \cdot \mbox{Var} \left (\beta_{xm} \right ) + 
                                                      2M \cdot \mbox{Cov} \left (\beta_x, \beta_{xm} \right )
\end{align}$$

---

# Incertitude et test d'hypothèse nulle

.column50-left[
La librairie `margins` dans `R` fait toutes ces opérations automatiquement.

```{r eval=FALSE}
library(margins)

margins(mod)

cplot(mod, x = 'M', dx = 'X', 
      what = 'effect')
```
]
.column50-right[
<center><img src='fig/graphique_18.3.png' width='100%'></center>
]

---

class: center middle

.f-headline.pink[Merci!]
