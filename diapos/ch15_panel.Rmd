---
output:
  xaringan::moon_reader:
    css: ["lib/fonts.css", "lib/slides.css"]   
    lib_dir: lib
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    seal: false
---

class: title
background-image: url(fig/wall_tomato.jpg)
background-size: cover

# ACMQ Ch.16 Observations répétées ou hiérarchiques

---

.massive[Observations répétées]

---

# Observations répétées

Un panel est une banque de données qui comprend plusieurs unités d'observation, et où les caractéristiques de chaque unité sont mesurées à plusieurs reprises. 

Le tableau montre le résultat de 3 élections fédérales canadiennes dans la circonscription de Brome--Missisquoi. Les unités d'observation sont les partis, observés à 3 reprises, lors des élections de 2008, 2011, et 2015.

<center><img src='fig/tableau_16.1.png' width='50%'></center>

---

# Observations répétées

Pour estimer la relation entre le genre des candidats et les votes reçus, la stratégie la plus simple serait un modèle linéaire comme celui-ci :

$$Y_{it} = \beta X_{it} + \alpha + \varepsilon_{it},$$

où $i$ identifie le parti politique, $t$ l'élection, $\beta$ le coefficient de régression, et $\alpha$ la constante du modèle.

Cette équation représente un modèle en "pooling" : elle met en commun toute la variation disponible dans les données. 

Ce modèle ignore la structure en panel en estimant la relation entre $X$ et $Y$ comme si les observations étaient indépendantes les unes des autres. 

---

# Observations répétées

Les données étudiées dans l'article "Do Women Get Fewer Votes? No." de Sevi, Arel-Bundock et Blais (2019) incluent des informations sur le genre et les votes reçus par près de 34000 candidats aux élections fédérales canadiennes (1921--2015): 

```{r eval=FALSE}
dat <- read.csv('data/sevi_arel-bundock_blais_2019.csv') 
```

Pour estimer si les candidates reçoivent moins de votes que les candidats, on estime un modèle de régression linéaire qui ignore la structure en panel des données.

La variable dépendante est le pourcentage des votes obtenus par un parti, dans une circonscription, lors d'une élection (entre 0 et 100). La variable indépendante est égale à 1 si la candidate est une femme et 0 autrement:

```{r eval=FALSE}
mod <- lm(votes ~ femme, data = dat)
coef(mod)['femme']
##     femme
## -8.400304
```

---

.massive[Effets fixes]

---

# Effets fixes

Les coefficients produits par un modèle de régression linéaire sont non biaisés seulement si $X$ est indépendant du terme d'erreur $\varepsilon$, c.-à-d. si $X$ est indépendant des variables omises qui influencent $Y$. 

Étudier des données en panel viole souvent ce postulat. 

Dans un panel, certains individus sont fondamentalement différents des autres ; les différences constantes et fondamentales entre individus sont souvent impossibles à mesurer ou à contrôler. 

Si les unités d'observation ont des caractéristiques propres et constantes qui déterminent les autres variables du modèle, et si on ne peut pas contrôler pour ces caractéristiques, le modèle en pooling risque d'être biaisé.

---

# Effets fixes

Certains partis politiques se sont dotés d'institutions paritaires et de règles pour faciliter le recrutement de femmes candidates. 

Si les partis les plus actifs dans ce dossier ont d'autres caractéristiques qui les rendent plus (ou moins) populaires lors des élections, les estimés pourraient souffrir de biais par variable omise:

<center><img src='fig/goa_16.1.png' width='40%'></center>

Pour éliminer ce biais par variable omise, on doit modéliser explicitement la structure en panel des données. 

Une stratégie puissante pour éliminer le biais par variable omise est le modèle de régression avec "effets fixes." 

---

## Spécification

Un effet fixe est le coefficient associé à une variable binaire égale à 1 pour une unité d'observation donnée, et 0 pour toutes les autres. Chaque unité d'observation est associée à son propre effet fixe.

<center><img src='fig/tableau_16.1.png' width='60%'></center>

---

## Spécification

Pour spécifier un modèle de régression avec effets fixes, il suffit d'ajouter ces variables binaires à l'équation de régression:

$$Y_{it} = \beta X_{it} + \alpha_1 B_i + \alpha_2 C_i + \alpha_3 L_i + \alpha_4 N_i + \varepsilon_{it},$$

où les coefficients de régression $\alpha_1, \alpha_2, \alpha_3$ et $\alpha_4$ sont appelés "effets fixes." 

Plus généralement, quand il y a $k$ unités d'observation, on écrit le modèle ainsi:

$$Y_{it} = \beta X_{it} + \sum_{i=1}^k \alpha_i + \varepsilon_{it}$$

Le modèle avec effets fixes estime un seul coefficient $\beta$. Peu importe l'unité d'observation, la relation estimée entre $X$ et $Y$ demeure la même. 

Ce modèle estime une constante différente pour chaque unité d'observation $(\alpha_i)$.

---

## Spécification

Une façon mathématiquement équivalente de spécifier le modèle avec effets fixes est: 

$$Y_{it} - \bar{Y}_i = \beta (X_{it} - \bar{X}_i) + \alpha + \varepsilon_{it},$$

où $\bar{Y}_i$ et $\bar{X}_i$ sont les moyennes de $Y$ et de $X$ pour l'unité $i$. 

Le modèle avec effets fixes peut être obtenu en soustrayant les moyennes de groupes des variables dépendante et indépendante, avant d'estimer le modèle linéaire.

---

## Interprétation

En permettant à chaque unité d'observation d'avoir sa propre constante, le modèle avec effets fixes contrôle pour tous les facteurs qui sont :
* propres à une unité d'observation, et
* constants entre les différentes périodes de mesure.

Au Canada, le Bloc Québécois est un parti politique séparatiste, et le Parti Libéral est un parti politique fédéraliste. 

Cette distinction entre les deux partis était vraie et constante lors de toutes les élections dans les données. 

Le modèle avec effets fixes contrôle pour cette différence.

---

## Interprétation

$$Y_{it} - \bar{Y}_i = \beta (X_{it} - \bar{X}_i) + \alpha + \varepsilon_{it},$$

En soustrayant les moyennes de groupe, le modèle "centre" toutes les variables, afin que chaque unité d'observation ait une moyenne de zéro. 

Cela permet d'éliminer toute la variation constante *entre* les individus de la banque de données. 

On exploite seulement les changements *au sein* des individus, au fil du temps.

Le modèle avec effets fixes permet de limiter certaines formes de biais par variable omise au prix d'ignorer de l'information qui pourrait être pertinente pour l'analyse.

---

## Interprétation

Un coefficient de régression dans un modèle avec effets fixes mesure l'association entre la variable dépendante et les mouvements de la variable indépendante qui ont lieu au sein d'une même unité d'analyse. 

Le modèle ignore la variance entre les unités de la banque de données. 

Un modèle avec une constante par individu (effets fixes) est plus flexible qu'un modèle avec une seule constante (pooling), et les deux approches peuvent produire des estimés radicalement différents du coefficient $\beta$. 

---

## Interprétation

<center><img src='fig/graphique_16.1.png' width='60%'></center>

Lorsque toute la variation est mise en commun, l'estimé du coefficient $\beta$ est positif. 

Lorsque le modèle s'intéresse seulement à la variation au sein des individus, l'estimé du coefficient $\beta$ est négatif.

---

## Estimation

Pour estimer un modèle de régression avec effets fixes dans `R`, on utilise la fonction `factor`. 

Cette fonction crée automatiquement une série de variables dichotomiques pour chacune des unités d'observation, et elle les inclut dans le modèle de régression.

Pour déterminer si les candidates reçoivent moins de votes que les candidats, on estime un modèle de régression linéaire avec effets fixes pour le parti :

```{r eval=FALSE}
mod <- lm(votes ~ femme + factor(parti), data = dat)
coef(mod)['femme']
##     femme
## -3.185686
```

Après avoir contrôlé pour les caractéristiques constantes des partis politiques, le modèle estime que la candidate moyenne reçoit 3,2 points de pourcentage de moins de votes que le candidat moyen.

---

## Effets fixes à plusieurs niveaux

Jusqu'à maintenant, nous avons seulement considéré les effets fixes au niveau de l'individu. Une autre possibilité est d'inclure des effets fixes à plusieurs niveaux. 

Par exemple, en plus d'inclure une variable dichotomique par parti politique, nous pourrions inclure une variable dichotomique par élection. 

Ce type de modèle contrôle à la fois pour les caractéristiques communes à toutes les observations faites sur un individu, et pour les caractéristiques communes à toutes les observations faites lors d'une période donnée.

---

## Effets fixes à plusieurs niveaux

Inclure des effets fixes pour chaque élection permet de contrôler pour les "chocs" qui ont pu affecter certaines élections, ainsi que pour les tendances temporelles dans nos variables d'intérêt:

```{r eval=FALSE}
mod <- lm(votes ~ femme + factor(parti) + factor(election), 
          data = dat)
coef(mod)['femme']
##   femme
## -1.6484
```

Ce modèle contrôle pour les effets de partis et les effets temporels. Il estime que la candidate moyenne reçoit 1,6 points de pourcentage de moins de votes que le candidat moyen.

---

## Limites des effets fixes

Le modèle à effets fixes est un outil puissant pour limiter le biais par variable omise dû à des facteurs non observables. 

Cependant, mettre l'accent sur la variation intra-individu impose aussi certaines contraintes.

---

## Limites des effets fixes

Il est mathématiquement impossible d'utiliser un modèle avec effets fixes pour estimer l'effet marginal de phénomènes qui ne varient pas au sein d'une unité d'observation.

Lorsqu'une variable change peu au sein d'un individu, il est possible d'estimer un modèle avec effets fixes, mais l'information disponible sera pauvre, et les erreurs types risquent d'être (correctement) grandes. 

<center><img src='fig/graphique_6.5_multicol.png' width='70%'></center>

---

## Limites des effets fixes

Le modèle avec effets fixes nous force à ignorer de l'information statistique qui pourrait être utile ou intéressante: il ignore l'information qu'un analyste peut extraire des comparaisons entre individus.

----

Les effets sont "fixes" au sens où ils ne varient pas entre les différentes mesures faites sur une même unité d'observation. 

L'effet fixe ne contrôle pas pour les dynamiques temporelles qui pourraient affecter nos résultats. 

Ce type de modèle ne sera pas approprié si la valeur de notre variable dépendante est fonction de la valeur de cette même variable lors des périodes d'observations précédentes.

---

.massive[Variable dépendante décalée]

---

# Variable dépendante décalée

<center><img src='fig/graphique_16.2a.png' width='30%'></center>

Ce graphique montre un exemple typique où le modèle avec effets fixes est approprié. 

La valeur de $Y$ est déterminée par la valeur contemporaine d'une variable $X$, qui change aux temps 1, 2, et 3. 

La valeur de $Y$ est aussi déterminée par un effet $U$, qui est constant au fil du temps.

---

# Variable dépendante décalée

<center><img src='fig/graphique_16.2b.png' width='30%'></center>

Ce graphique montre un exemple où le processus de génération des données ne se conforme *pas* au modèle simple avec effets fixes. 

La valeur de $Y$ est déterminée par la valeur de $Y$ lors des périodes précédentes. 

$Y_{t=1}$ détermine $Y_{t=2}$, et $Y_{t=2}$ détermine $Y_{t=3}$.

---

# Variable dépendante décalée

Une approche populaire pour tenir compte des dynamiques temporelles est d'estimer un modèle de cette forme :

$$Y_{it} = \beta_0 + \beta_1 X_{it} + \beta_2 Y_{it-1} + \varepsilon_{it},$$

où $Y_{it-1}$ est une variable dépendante décalée.

<center><img src='fig/tableau_16.1.png' width='53%'></center>

---

# Variable dépendante décalée

Pour estimer un modèle avec variable décalée, il suffit de traiter celle-ci comme une variable de contrôle :

```{r eval=FALSE}
mod <- lm(votes ~ femme + votes_decales, data = dat)
coef
##   (Intercept)       femme  votes_decales
##     3.8771606  -1.8668021      0.8488553
```

Ce modèle estime qu'en moyenne, la part des votes obtenus par une femme candidate est 1,87 moins élevée que celle des hommes.

---

# Combiner les effets fixes et les variables décalées

<center><img src='fig/graphique_16.2c.png' width='25%'></center>

Ce graphique montre un modèle causal où il y a un effet unitaire constant *et* un effet dynamique. 

On pourrait être tenté de combiner les effets fixes à une variable décalée, pour estimer un modèle de cette forme:

$$Y_{it} = \beta_1 X_{it} + \beta_2 Y_{it-1} + \sum_{i=1}^k \alpha_i + \varepsilon_{it}$$
Ce type de modèle produit généralement un estimé biaisé du coefficient $\beta_1$.

---

# Combiner les effets fixes et les variables décalées

$$\begin{align*}
Y_{it} &= \beta_1 X_{it} + \beta_2 Y_{it-1} + \sum_{i=1}^k \alpha_i + \varepsilon_{it} &\mbox{(1)}\\
Y_{it} &= \beta X_{it} + \sum_{i=1}^k \alpha_i + \varepsilon_{it} &\mbox{(2)}\\
Y_{it} &= \beta_0 + \beta_1 X_{it} + \beta_2 Y_{it-1} + \varepsilon_{it} &\mbox{(3)}
\end{align*}$$

Combiner les effets fixes et les variables décalées n'est pas recommandé en pratique, surtout quand le nombre d'observations par unité est petit.

Si le vrai modèle qui a généré les données est bien représenté par l'équation 1, estimer le modèle 2 aura tendance à surestimer la taille d'un effet de traitement positif. 

Estimer le modèle 3 aura tendance à sous-estimer la taille d'un effet de traitement positif. 

Par conséquent, les modèles avec effets fixes et variable décalée bornent l'intervalle dans lequel se trouve le bon estimé de $\beta_1$.

---

.massive[Méthode des doubles différences]

---

# Méthode des doubles différences

La méthode des doubles différences est une stratégie empirique alternative pour exploiter les données en panel. 

Cette méthode repose sur une comparaison entre la valeur d'une variable dépendante dans les groupes de traitement et de contrôle, avant et après l'administration dudit traitement. 

La méthode tient son nom du double contraste qui fait l'objet de l'analyse: nous mesurons la différence dans la différence entre les groupes expérimentaux, avant et après le traitement.

---

# Méthode des doubles différences

<center><img src='fig/graphique_16.3.png' width='70%'></center>

---

# Méthode des doubles différences

<center><img src='fig/graphique_16.4.png' width='58%'></center>

---

## Postulat: Tendance commune

Pour donner une interprétation causale à une analyse par méthode des doubles différences, il faut postuler qu'en l'absence de traitement, les groupes de traitement et de contrôle auraient suivi une *tendance commune*. 

Les groupes de traitement et de contrôle auraient suivi des trajectoires parallèles dans le monde contre-factuel où aucun traitement n'aurait été administré.

Ce postulat est relativement permissif :
* Les groupes de traitement et de contrôle peuvent être systématiquement différents, tant que cette différence demeure constante au fil du temps. 
* Toutes les unités d'observation peuvent changer au fil du temps, tant que le temps affecte les groupes de contrôle et de traitement de la même façon.

---

## Postulat: Tendance commune

La méthode des doubles différences ne permet pas d'échapper au problème fondamental de l'inférence causale. 

Le postulat des tendances communes fait appel à une hypothèse contre-factuelle impossible à démontrer.

Pour convaincre le lecteur que le postulat de tendance commune est raisonnable, plusieurs chercheurs démontrent empiriquement que les groupes de traitement et de contrôle évoluaient en parallèle dans la période prétraitement. 

Cette analyse ne doit pas être interprétée comme une démonstration du postulat fondamentalement contre-factuel de la méthode des doubles différences.

---

## Estimation

Cord et Krueger (1994) tentent d’estimer l’effet causal d’une augmentation du salaire minimum sur le nombre d’emplois dans la restauration rapide.

En 1992, le gouvernement du New Jersey a haussé le salaire minimum de 4.25$ à 5.05$ par heure.

Plusieurs économistes s'attendaient alors à ce que les employeurs réagissent en réduisant le nombre d'emplois offerts. 

Pour tester cette hypothèse, les auteurs ont amassé de l'information sur le nombre d'emplois à temps plein dans la restauration rapide au New Jersey et dans l'est de la Pennsylvanie.

---

## Estimation

<center><img src='fig/graphique_16.5.png' width='60%'></center>

---

## Estimation

```{r eval=FALSE}
dat <- read.csv('data/card_krueger_1994.csv')
```

Pour mesurer la différence des différences, nous calculons d'abord la moyenne du nombre d'emplois à temps plein, dans chaque état, pour chaque période:

```{r eval=FALSE}
dat %>% group_by(etat, periode) %>%
        summarize(emplois_moyens = mean(emplois))
## # A tibble: 4 x 3
## # Groups:   etat [2]
##   etat         periode emplois_moyens
##   <chr>          <int>          <dbl>
## 1 New Jersey         0           20.4
## 2 New Jersey         1           21.0
## 3 Pennsylvania       0           23.3
## 4 Pennsylvania       1           21.2
```

---

## Estimation

<center><img src='fig/graphique_16.6.png' width='60%'></center>

---

## Estimation

Le nombre
d’emplois moyens dans les restaurants avant l’augmentation du salaire minimum était de 20,4 au New Jersey et de 23,3 en Pennsylvanie. La différence entre les deux états était de 2,9.

Le nombre d’emplois moyens dans les restaurants après l’augmentation du salaire minimum était de 21,0 au New Jersey et de 21,2 en Pennsylvanie. La différence entre les deux états était de 0,1.

La différence des différences est égale à 2,8. 

Cette quantité mesure l’effet de traitement moyen.

---

## Estimation

Dans un cas simple avec un traitement binaire et seulement deux périodes d'observation, l'estimé causal par méthode des doubles différences peut être calculé avec un modèle de régression à deux niveaux d'effets fixes:

$$Y_{it} = \beta_1 X_i + \sum_{i=1}^n \alpha_i + \sum_{t=1}^k \lambda_j + \varepsilon_{it},$$

o$Y_{it}$ est le nombre d'emplois dans le restaurant $i$ lors de la période $t$

$X_i$ est égal à 1 pour les restaurants du New Jersey après l'augmentation du salaire minimum et 0 autrement

$\alpha_i$ sont des effets fixes pour les états

 $\lambda_t$ sont des effets fixes de périodes (c.-à-d. avant et après le traitement).
 
---

## Estimation

Dans `R`, nous utilisons les fonctions `factor` et `lm`:

```{r eval=FALSE}
mod <- lm(emplois ~ salaire_minimum + 
          factor(etat) + factor(periode),
          data = dat)
summary(mod)
##                           Estimate Std. Error t value Pr(>|t|)
## (Intercept)                 20.439      0.525  38.934   <2e-16
## salaire_minimum              2.754      1.688   1.631   0.1033
## factor(etat)Pennsylvania     2.892      1.194   2.423   0.0156
## factor(periode)1            -2.166      1.516  -1.429   0.1535
```

L'estimé produit par ce modèle est exactement égal à la différence des différences calculée manuellement.

---

## Estimation

$$Y_{it} = \beta_1 X_i + \sum_{i=1}^n \alpha_i + \sum_{t=1}^k \lambda_j + \varepsilon_{it},$$

Ce modèle, avec effets fixes pour les unités et pour les périodes, est facile à appliquer aux cas où : 
* il y a plus que deux observations, 
* plus de deux mesures sont prises par unité, 
* le traitement n'est pas administré à toutes les unités en même temps. 

Plusieurs analystes interprètent les résultats produits par ce modèle comme un estimé causal par méthode des doubles différences "généralisée."

Une interprétation strictement correcte requiert plus de nuance.

---

.massive[Régression multiniveau]

---

# Régression multiniveau

Souvent, une banque de données est structurée de façon hiérarchique, ou les individus observés font partie de groupes clairement identifiables. 

> Par exemple, un chercheur qui veut estimer l'effet d'un nouvel outil pédagogique sur la performance scolaire pourrait observer un grand échantillon d'élèves de l'école primaire. 

> Ces élèves font partie de groupes imbriqués les uns dans les autres, de façon hiérarchique: une classe dans une école, dans une ville, dans une province, dans un pays. 

> Les élèves d'une seule classe risquent d'être plus homogènes que les élèves de toute une ville. 

Le modèle de régression multiniveau tient en compte l'interdépendance entre les observations d'un échantillon, et exploite la structure hiérarchique des données afin de mieux estimer la relation d'intérêt.

---

# Régression multiniveau

L'expression "multiniveau" réfère à une classe de modèles qui se distinguent de la régression linéaire simple par la présence de "composantes aléatoires".

Un chercheur tente d'estimer l'effet de $X$ sur $Y$ ; il assemble des données sur $n$ individus répartis dans $j$ groupes et estime ce modèle de régression linéaire :

$$Y_{ik} = \alpha + \beta X_{ik} + \varepsilon_{ik},$$

où $\alpha$ est la constante et $\beta$ le coefficient de régression. 

Les termes $Y$, $X$ et $\varepsilon$ sont marqués de l'indice "$ik$" pour souligner que l'individu $i$ fait partie du groupe $k$. 

---

# Régression multiniveau

$$Y_{ik} = \alpha + \beta X_{ik} + \varepsilon_{ik},$$

Ce modèle assume que la constante et le coefficient sont identiques pour tous les groupes. 

Ce postulat est parfois irréaliste. 

Par exemple, quand la variable dépendante est (conditionnellement) plus élevée dans certains groupes, un modèle avec une seule constante représente mal le processus de génération des données. 

Pour améliorer ce modèle, le chercheur peut estimer un modèle multiniveau avec "ordonnées à l'origine aléatoires":

$$Y_{ik} = \alpha_k + \beta X_{ik} + \varepsilon_{ik}$$

---

# Régression multiniveau

$$Y_{ik} = \alpha_k + \beta X_{ik} + \varepsilon_{ik} \hspace{1in} \mbox{Random Intercepts}$$

Dans ce modèle, chaque groupe $k$ est associé à une ordonnée à l'origine distincte: $\alpha_k$. 

Ce modèle fait différentes prédictions pour la variable dépendante dans les différents groupes de l'échantillon.

Les paramètres $\alpha_k$ sont analogues aux effets unitaires du modèle de régression avec effets fixes, mais ils sont estimés différemment. 

Plutôt que d'insérer une variable dichotomique par unité d'observation dans l'équation de régression, le modèle multiniveau estime $\alpha_k$ en exploitant deux postulats statistiques: 
1. Toutes les valeurs de $\alpha_k$ sont tirées d'une même distribution, 
2. Les effets unitaires $\alpha_k$ sont indépendants des variables omises $\varepsilon$.

Lorsque ces postulats sont satisfaits, le modèle multiniveau avec ordonnées à l'origine aléatoires tient compte des différences de groupe dans le niveau de $Y$.

---

# Régression multiniveau

Le modèle multiniveau permet aussi de modéliser un second type d'interdépendance entre les unités d'observation. 

Parfois, la relation entre $X$ et $Y$ varie d'un groupe à l'autre :
* Dans certains groupes, une augmentation de $X$ pourrait être associée à une *augmentation* de $Y$.
* Dans d'autres groupes, une augmentation de $X$ pourrait être associée à une *diminution* de $Y$ (ou à une augmentation moins élevée de $Y$). 

Pour capturer cette hétérogénéité, le chercheur peut estimer un modèle multiniveau avec "pentes aléatoires":

$$Y_{ik} = \alpha + \beta_k X_{ik} + \varepsilon_{ik} \hspace{1in} \mbox{Random Slopes}$$

Dans ce modèle, chaque groupe $k$ est associé à un coefficient de régression distinct: $\beta_k$. 

Ceci permet à la relation entre $X$ et $Y$ de varier d'un groupe à l'autre.

---

# Régression multiniveau

$$\begin{align*} 
Y_{ik} &= \alpha_k + \beta X_{ik} + \varepsilon_{ik} &\mbox{Random Intercepts} \\
Y_{ik} &= \alpha + \beta_k X_{ik} + \varepsilon_{ik} &\mbox{Random Slopes} 
\end{align*}$$

Si on croit que les deux formes de dépendance sont présentes dans l'échantillon, on pourrait combiner les deux modèles pour estimer un modèle avec ordonnées à l'origine et pentes aléatoires: 

$$Y_{ik} = \alpha_k + \beta_k X_{ik} + \varepsilon_{ik} \hspace{1in} \mbox{Random Intercepts & Slopes}$$

En pratique, lorsqu'on estime ce modèle, la procédure statistique produira des estimés distincts pour la constante et le coefficient dans chacun des groupes qui composent l'échantillon. 

Pour 900 élèves répartis dans 30 classes, ce modèle estimerait 30 constantes et 30 coefficients différents.

---

## Exemple

> Les personnes qui voyagent ont des attitudes plus favorables quant à l'immigration que les personnes qui ne voyagent pas.

Nous allons tester cette hypothèse à l'aide de données recueillies par sondage dans le cadre de l'Eurobaromètre, une grande enquête pan-européenne.

Notre banque de données contient de l'information sur plus de 26000 individus, dans 30 pays. 

```{r eval=FALSE}
dat <- read.csv('data/eurobarometre.csv')
```

---

## Exemple

```{r eval=FALSE}
head(dat)
##                  pays immigration visite
## 14293   Great Britain           2      1
## 22837         Romania           3      0
## 24973       Slovenija           1      1
## 1376          Danmark           1      1
## 16367 Ceska Republika           1      0
## 10680         Portugal          1      1
```


`pays`: le pays de résidence

`immigration`: l'attitude envers les immigrants d'autres pays de l'UE, de 0 (très négatif) à 3 (très positif).

`visite`: une dummy égale à 1 si le répondant a visité un autre pays de l'UE au cours des 12 derniers mois.

---

## Exemple

La fonction `lmer` de la librairie `lme4` permet d'analyser ces données.

```{r eval=FALSE}
library(lme4)

# Constante aléatoire
mod1 <- lmer(immigration ~ visite + (1 | pays), data = dat)

# Coefficient aléatoire
mod2 <- lmer(immigration ~ visite + (visite | pays), data = dat)

# Constante et coefficient aléatoires
mod3 <- lmer(immigration ~ visite + (1 + visite | pays), data = dat)
```

La dernière commande estime un modèle avec :
* `immigration` comme variable dépendante,
* `visite` comme variable indépendante,
* des constantes et coefficients distincts pour chacun des 30 `pays` de l'échantillon. 

---

## Exemple

<center><img src='fig/tableau_16.2.png' width='55%'></center>

---

## Exemple

La commande `summary` permet de résumer les estimés d'un modèle multiniveau:

```{r eval=FALSE}
summary(mod3)
##
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  1.08536    0.05532  19.619
## visite       0.19289    0.02829   6.819
##
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  pays     (Intercept) 0.08983  0.2997
##           visite      0.02017  0.1420   -0.12
##  Residual             0.66107  0.8131
##
## Number of obs: 26233, groups: pays, 30
```

---

# Multiniveau vs. Échantillon complet vs. Sous-groupes

Pour développer une meilleure intuition quant à la nature des composantes aléatoires, il est utile de comparer trois approches alternatives: 
1. Modèle dans l'échantillon complet 
2. Modèles par sous-groupes
3. Modèle multiniveau

---

## 1. Modèle dans l'échantillon complet 

Cette approche est la plus simple: estimer la relation entre la variable dépendante et la variable indépendante dans l'échantillon complet, sans tenir compte de l'interdépendance des observations faites au sein d'un même groupe. 

Pour ce faire, nous estimons un simple modèle de régression linéaire avec la fonction `lm`:

```{r eval=FALSE}
mod <- lm(immigration ~ visite, data = dat)
coef(mod)
## (Intercept)     visite
##    1.059641   0.241871
```

Dans ce modèle, la constante et le coefficient sont les mêmes pour tous les pays. 

> Par exemple, la relation entre le voyage et l'appui à l'immigration est exactement la même pour les Espagnols que pour les Danois.

---

## 2. Modèles par sous-groupes

Cette approche consiste à diviser l'échantillon en 30 parties (une pour chaque pays), et à estimer un modèle de régression différent dans chacun des 30 sous-groupes. 

Avec cette approche, les données assemblées sur un groupe d'observations n'ont aucune influence sur les paramètres estimés dans les autres groupes. 

Les réponses au sondage des citoyens autrichiens n'ont aucun effet sur les estimés de régression dans l'échantillon hongrois.

---

## 3. Modèle multiniveau

Cette approche estime un modèle de régression multiniveau avec constante et coefficient aléatoires. 

Même si le modèle multiniveau estime un coefficient distinct pour chacun des groupes, ces coefficients ne sont pas complètement indépendants les uns des autres. 

Cette approche postule que les composantes aléatoires sont toutes issues d'une seule et même distribution. 

Le coefficient estimé pour un groupe a donc une influence sur les autres groupes, à travers son influence sur les paramètres de la distribution sous-jacente. 

---

## 3. Modèle multiniveau

Intuitivement, le modèle multiniveau considère que les données observées dans un sous-groupe offrent de l'information pertinente pour l'analyse des autres sous-groupes. 

> Par exemple, si on observe une relation positive entre les voyages et les attitudes pro-immigration en Finlande, en Espagne, et en Hongrie, il serait raisonnable de prédire que cette relation est positive en Italie.

Un modèle multiniveau permet aux coefficients estimés dans un sous-groupe d'informer l'estimation des coefficients dans les autres sous-groupes.

Puisqu’une composante aléatoire estimée dans un groupe est influencée par les composantes aléatoires estimées dans les autres groupes, le coefficient multiniveau aura tendance à être "tiré" vers la moyenne globale. 

En général, ce retour à la moyenne sera plus marqué pour les groupes où le nombre d'observations est faible, et dans les groupes où le coefficient estimé est extrême.

---

## 3. Modèle multiniveau

<center><img src='fig/graphique_16.7.png' width='50%'></center>

---

## 3. Modèle multiniveau

Les estimés multiniveau sont similaires aux estimés obtenus en réestimant un modèle identique et indépendant dans les 30 groupes. 

Par contre, pour certains pays, les estimés de la constante et du coefficient se sont déplacés vers le centre, comme si ils étaient attirés par la croix. 

Ces estimés exploitent le pouvoir explicatif des observations dans les autres groupes pour mieux s'ajuster aux données.

---

# Avantages et inconvénients

Les modèles de régression multiniveau avec composantes aléatoires ont plusieurs avantages :

1. En portant attention à la valeur des paramètres dans différents sous-groupes, ce type de modèle peut souvent faire de bonnes prédictions. 
2. Le modèle multiniveau exploite des informations sur l'ensemble de l'échantillon pour estimer les paramètres d'un sous-groupe ; les estimés ainsi produits sont parfois plus efficients que ceux des modèles alternatifs. 

3. Le modèle multiniveau est utile, parce qu'il permet d'estimer directement l'hétérogénéité entre les groupes qui composent notre échantillon. 

4. Ce modèle peut être modifié pour analyser différents types de variables dépendantes, augmenté pour laisser varier les composantes aléatoires sur plusieurs niveaux à la fois, etc.
 
---

# Avantages et inconvénients

$$\begin{align*} 
Y_{ik} &= \alpha_k + \beta X_{ik} + \varepsilon_{ik} &\mbox{Random Intercepts} \\
Y_{ik} &= \alpha + \beta_k X_{ik} + \varepsilon_{ik} &\mbox{Random Slopes} \\
Y_{ik} &= \alpha_k + \beta_k X_{ik} + \varepsilon_{ik} &\mbox{Random Intercepts & Slopes}
\end{align*}$$

Certains des postulats qui sous-tendent le modèle multiniveau sont irréalistes. 

Le modèle avec ordonnées à l'origine aléatoires est biaisé lorsque les effets unitaires $(\alpha_k)$ sont associés à $X$.

Le modèle multiniveau nous force à accepter plusieurs postulats auxiliaires, notamment sur l'indépendance des composantes aléatoires et des variables omises, et sur la distribution des résidus.

Lorsque ces postulats sont violés, le modèle de régression multiniveau pourrait être biaisé, et le modèle avec effets fixes pourrait produire de meilleurs résultats.
